{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74904c58-b413-4a2b-a80b-b6afc65bb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q torch-geometric==2.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddca0cd5-8212-4779-8125-6798b0760ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q ogb==1.3.6 # graph benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f5036b-5554-406c-b251-2a7256794951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.seed import seed_everything\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import CitationFull, Coauthor, Flickr, RelLinkPredDataset, WordNet18, WordNet18RR\n",
    "from torch_geometric.utils import train_test_split_edges, k_hop_subgraph, negative_sampling, to_undirected, is_undirected, to_networkx\n",
    "from ogb.linkproppred import PygLinkPropPredDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7fd00-1a2e-4ba9-b975-a6412ef67338",
   "metadata": {},
   "source": [
    "# Define the utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2523dad8-b250-47ec-b34e-d9f50a5d3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def get_node_edge(graph):\n",
    "    degree_sorted_ascend = sorted(graph.degree, key=lambda x: x[1])\n",
    "\n",
    "    return degree_sorted_ascend[-1][0]\n",
    "\n",
    "def h_hop_neighbor(G, node, h):\n",
    "    path_lengths = nx.single_source_dijkstra_path_length(G, node)\n",
    "    return [node for node, length in path_lengths.items() if length == h]\n",
    "                    \n",
    "def get_enclosing_subgraph(graph, edge_to_delete):\n",
    "    subgraph = {0: [edge_to_delete]}\n",
    "    s, t = edge_to_delete\n",
    "    \n",
    "    neighbor_s = []\n",
    "    neighbor_t = []\n",
    "    for h in range(1, 2+1):\n",
    "        neighbor_s += h_hop_neighbor(graph, s, h)\n",
    "        neighbor_t += h_hop_neighbor(graph, t, h)\n",
    "        \n",
    "        nodes = neighbor_s + neighbor_t + [s, t]\n",
    "        \n",
    "        subgraph[h] = list(graph.subgraph(nodes).edges())\n",
    "        \n",
    "    return subgraph\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float, device=pos_edge_index.device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_link_labels_kg(pos_edge_index, neg_edge_index):\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float, device=pos_edge_index.device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "\n",
    "    return link_labels\n",
    "\n",
    "@torch.no_grad()\n",
    "def negative_sampling_kg(edge_index, edge_type):\n",
    "    '''Generate negative samples but keep the node type the same'''\n",
    "\n",
    "    edge_index_copy = edge_index.clone()\n",
    "    for et in edge_type.unique():\n",
    "        mask = (edge_type == et)\n",
    "        old_source = edge_index_copy[0, mask]\n",
    "        new_index = torch.randperm(old_source.shape[0])\n",
    "        new_source = old_source[new_index]\n",
    "        edge_index_copy[0, mask] = new_source\n",
    "    \n",
    "    return edge_index_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44892f52-2979-4da5-8f47-38863e1495b5",
   "metadata": {},
   "source": [
    "# Define split data to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2a79dc-457d-4434-968e-9118f432d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "\n",
    "df_size = [i / 100 for i in range(10)] + [i / 10 for i in range(10)] + [i for i in range(10)]       # Df_size in percentage\n",
    "seeds = [42, 21, 13, 87, 100]\n",
    "graph_datasets = ['Cora', 'PubMed', 'DBLP', 'CS', 'ogbl-citation2', 'ogbl-collab'][4:]\n",
    "kg_datasets = ['FB15k-237', 'WordNet18', 'WordNet18RR', 'ogbl-biokg'][-1:]\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "num_edge_type_mapping = {\n",
    "    'FB15k-237': 237,\n",
    "    'WordNet18': 18,\n",
    "    'WordNet18RR': 11\n",
    "}\n",
    "\n",
    "def train_test_split_edges_no_neg_adj_mask(data, val_ratio: float = 0.05, test_ratio: float = 0.1, two_hop_degree=None, kg=False):\n",
    "    '''Avoid adding neg_adj_mask'''\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    row, col = data.edge_index\n",
    "    edge_attr = data.edge_attr\n",
    "    if kg:\n",
    "        edge_type = data.edge_type\n",
    "    data.edge_index = data.edge_attr = data.edge_weight = data.edge_year = data.edge_type = None\n",
    "\n",
    "    if not kg:\n",
    "        # Return upper triangular portion.\n",
    "        mask = row < col\n",
    "        row, col = row[mask], col[mask]\n",
    "\n",
    "        if edge_attr is not None:\n",
    "            edge_attr = edge_attr[mask]\n",
    "\n",
    "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
    "    n_t = int(math.floor(test_ratio * row.size(0)))\n",
    "\n",
    "    if two_hop_degree is not None:          # Use low degree edges for test sets\n",
    "        low_degree_mask = two_hop_degree < 50\n",
    "\n",
    "        low = low_degree_mask.nonzero().squeeze()\n",
    "        high = (~low_degree_mask).nonzero().squeeze()\n",
    "\n",
    "        low = low[torch.randperm(low.size(0))]\n",
    "        high = high[torch.randperm(high.size(0))]\n",
    "\n",
    "        perm = torch.cat([low, high])\n",
    "\n",
    "    else:\n",
    "        perm = torch.randperm(row.size(0))\n",
    "\n",
    "    row = row[perm]\n",
    "    col = col[perm]\n",
    "\n",
    "    # Train\n",
    "    r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
    "    \n",
    "    if kg:\n",
    "\n",
    "        # data.edge_index and data.edge_type has reverse edges and edge types for message passing\n",
    "        pos_edge_index = torch.stack([r, c], dim=0)\n",
    "        # rev_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "        train_edge_type = edge_type[n_v + n_t:]\n",
    "        # train_rev_edge_type = edge_type[n_v + n_t:] + edge_type.unique().shape[0]\n",
    "\n",
    "        # data.edge_index = torch.cat((torch.stack([r, c], dim=0), torch.stack([r, c], dim=0)), dim=1)\n",
    "        # data.edge_type = torch.cat([train_edge_type, train_rev_edge_type], dim=0)\n",
    "\n",
    "        data.edge_index = pos_edge_index\n",
    "        data.edge_type = train_edge_type\n",
    "        \n",
    "        # data.train_pos_edge_index and data.train_edge_type only has one direction edges and edge types for decoding\n",
    "        data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "        data.train_edge_type = train_edge_type\n",
    "    \n",
    "    else:\n",
    "        data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "        if edge_attr is not None:\n",
    "            # out = to_undirected(data.train_pos_edge_index, edge_attr[n_v + n_t:])\n",
    "            data.train_pos_edge_index, data.train_pos_edge_attr = out\n",
    "        else:\n",
    "            data.train_pos_edge_index = data.train_pos_edge_index\n",
    "            # data.train_pos_edge_index = to_undirected(data.train_pos_edge_index)\n",
    "        \n",
    "        assert not is_undirected(data.train_pos_edge_index)\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    r, c = row[:n_t], col[:n_t]\n",
    "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "\n",
    "    if kg:\n",
    "        data.test_edge_type = edge_type[:n_t]\n",
    "        neg_edge_index = negative_sampling_kg(\n",
    "            edge_index=data.test_pos_edge_index,\n",
    "            edge_type=data.test_edge_type)\n",
    "    else:\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=data.test_pos_edge_index,\n",
    "            num_nodes=data.num_nodes,\n",
    "            num_neg_samples=data.test_pos_edge_index.shape[1])\n",
    "\n",
    "    data.test_neg_edge_index = neg_edge_index\n",
    "\n",
    "    # Valid\n",
    "    r, c = row[n_t:n_t+n_v], col[n_t:n_t+n_v]\n",
    "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "\n",
    "    if kg:\n",
    "        data.val_edge_type = edge_type[n_t:n_t+n_v]\n",
    "        neg_edge_index = negative_sampling_kg(\n",
    "            edge_index=data.val_pos_edge_index,\n",
    "            edge_type=data.val_edge_type)\n",
    "    else:\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=data.val_pos_edge_index,\n",
    "            num_nodes=data.num_nodes,\n",
    "            num_neg_samples=data.val_pos_edge_index.shape[1])\n",
    "\n",
    "    data.val_neg_edge_index = neg_edge_index\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f21f4e-f84e-4616-87b1-bb057f551161",
   "metadata": {},
   "source": [
    "# Pre-process graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4583d531-27d7-4ebe-84a7-c11e8b8f0dcf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "This will download 2.14GB. Will you proceed? (y/N)\n",
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/linkproppred/citation-v2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 2.14 GB: 100%|██████████| 2189/2189 [02:10<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/ogbl-citation2/citation-v2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ogbl-citation2\n",
      "PygLinkPropPredDataset()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Two hop neighbors: 100%|██████████| 2927963/2927963 [03:04<00:00, 15851.68it/s]\n",
      "100%|██████████| 15228622/15228622 [08:11<00:00, 31001.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Data(num_nodes=2927963, x=[2927963, 128], node_year=[2927963, 1], train_pos_edge_index=[2, 13705760], test_pos_edge_index=[2, 761431], test_neg_edge_index=[2, 761431], val_pos_edge_index=[2, 761431], val_neg_edge_index=[2, 761431])\n",
      "Number of edges. Local:  10304632 Distant: 3401128\n",
      "21 Data(num_nodes=2927963, x=[2927963, 128], node_year=[2927963, 1], train_pos_edge_index=[2, 13705760], test_pos_edge_index=[2, 761431], test_neg_edge_index=[2, 761431], val_pos_edge_index=[2, 761431], val_neg_edge_index=[2, 761431])\n",
      "Number of edges. Local:  10304406 Distant: 3401354\n",
      "13 Data(num_nodes=2927963, x=[2927963, 128], node_year=[2927963, 1], train_pos_edge_index=[2, 13705760], test_pos_edge_index=[2, 761431], test_neg_edge_index=[2, 761431], val_pos_edge_index=[2, 761431], val_neg_edge_index=[2, 761431])\n",
      "Number of edges. Local:  10319833 Distant: 3385927\n",
      "87 Data(num_nodes=2927963, x=[2927963, 128], node_year=[2927963, 1], train_pos_edge_index=[2, 13705760], test_pos_edge_index=[2, 761431], test_neg_edge_index=[2, 761431], val_pos_edge_index=[2, 761431], val_neg_edge_index=[2, 761431])\n",
      "Number of edges. Local:  10299858 Distant: 3405902\n",
      "100 Data(num_nodes=2927963, x=[2927963, 128], node_year=[2927963, 1], train_pos_edge_index=[2, 13705760], test_pos_edge_index=[2, 761431], test_neg_edge_index=[2, 761431], val_pos_edge_index=[2, 761431], val_neg_edge_index=[2, 761431])\n",
      "Number of edges. Local:  10305197 Distant: 3400563\n",
      "Downloading http://snap.stanford.edu/ogb/data/linkproppred/collab.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.11 GB: 100%|██████████| 117/117 [00:08<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/ogbl-collab/collab.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 55.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 7073.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ogbl-collab\n",
      "PygLinkPropPredDataset()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Two hop neighbors: 100%|██████████| 235868/235868 [00:28<00:00, 8255.64it/s] \n",
      "100%|██████████| 1179052/1179052 [01:24<00:00, 13966.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Data(num_nodes=235868, x=[235868, 128], train_pos_edge_index=[2, 1061148], test_pos_edge_index=[2, 58952], test_neg_edge_index=[2, 58952], val_pos_edge_index=[2, 58952], val_neg_edge_index=[2, 58952])\n",
      "Number of edges. Local:  299852 Distant: 761296\n",
      "21 Data(num_nodes=235868, x=[235868, 128], train_pos_edge_index=[2, 1061148], test_pos_edge_index=[2, 58952], test_neg_edge_index=[2, 58952], val_pos_edge_index=[2, 58952], val_neg_edge_index=[2, 58952])\n",
      "Number of edges. Local:  302507 Distant: 758641\n",
      "13 Data(num_nodes=235868, x=[235868, 128], train_pos_edge_index=[2, 1061148], test_pos_edge_index=[2, 58952], test_neg_edge_index=[2, 58952], val_pos_edge_index=[2, 58952], val_neg_edge_index=[2, 58952])\n",
      "Number of edges. Local:  302993 Distant: 758155\n",
      "87 Data(num_nodes=235868, x=[235868, 128], train_pos_edge_index=[2, 1061148], test_pos_edge_index=[2, 58952], test_neg_edge_index=[2, 58952], val_pos_edge_index=[2, 58952], val_neg_edge_index=[2, 58952])\n",
      "Number of edges. Local:  304415 Distant: 756733\n",
      "100 Data(num_nodes=235868, x=[235868, 128], train_pos_edge_index=[2, 1061148], test_pos_edge_index=[2, 58952], test_neg_edge_index=[2, 58952], val_pos_edge_index=[2, 58952], val_neg_edge_index=[2, 58952])\n",
      "Number of edges. Local:  302658 Distant: 758490\n"
     ]
    }
   ],
   "source": [
    "def process_graph():\n",
    "    for d in graph_datasets:\n",
    "\n",
    "        if d in ['Cora', 'PubMed', 'DBLP']:\n",
    "            dataset = CitationFull(os.path.join(data_dir, d), d, transform=T.NormalizeFeatures())\n",
    "        elif d in ['CS', 'Physics']:\n",
    "            dataset = Coauthor(os.path.join(data_dir, d), d, transform=T.NormalizeFeatures())\n",
    "        elif d in ['Flickr']:\n",
    "            dataset = Flickr(os.path.join(data_dir, d), transform=T.NormalizeFeatures())\n",
    "        elif 'ogbl' in d:\n",
    "            dataset = PygLinkPropPredDataset(root=os.path.join(data_dir, d), name=d)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        print('Processing:', d)\n",
    "        print(dataset)\n",
    "        data = dataset[0]\n",
    "        data.train_mask = data.val_mask = data.test_mask = None\n",
    "        graph = to_networkx(data)\n",
    "\n",
    "        # Get two hop degree for all nodes\n",
    "        node_to_neighbors = {}\n",
    "        for n in tqdm(graph.nodes(), desc='Two hop neighbors'):\n",
    "            neighbor_1 = set(graph.neighbors(n))\n",
    "            neighbor_2 = sum([list(graph.neighbors(i)) for i in neighbor_1], [])\n",
    "            neighbor_2 = set(neighbor_2)\n",
    "            neighbor = neighbor_1 | neighbor_2\n",
    "            \n",
    "            node_to_neighbors[n] = neighbor\n",
    "\n",
    "        two_hop_degree = []\n",
    "        row, col = data.edge_index\n",
    "        mask = row < col\n",
    "        row, col = row[mask], col[mask]\n",
    "        for r, c in tqdm(zip(row, col), total=len(row)):\n",
    "            neighbor_row = node_to_neighbors[r.item()]\n",
    "            neighbor_col = node_to_neighbors[c.item()]\n",
    "            neighbor = neighbor_row | neighbor_col\n",
    "            \n",
    "            num = len(neighbor)\n",
    "            \n",
    "            two_hop_degree.append(num)\n",
    "\n",
    "        two_hop_degree = torch.tensor(two_hop_degree)\n",
    "\n",
    "        for s in seeds:\n",
    "            seed_everything(s)\n",
    "\n",
    "            # D\n",
    "            data = dataset[0]\n",
    "            if 'ogbl' in d:\n",
    "                data = train_test_split_edges_no_neg_adj_mask(data, test_ratio=0.05, two_hop_degree=two_hop_degree)\n",
    "            else:\n",
    "                data = train_test_split_edges_no_neg_adj_mask(data, test_ratio=0.05)\n",
    "            print(s, data)\n",
    "\n",
    "            with open(os.path.join(data_dir, d, f'd_{s}.pkl'), 'wb') as f:\n",
    "                pickle.dump((dataset, data), f)\n",
    "\n",
    "            # Two ways to sample Df from the training set\n",
    "            ## 1. Df is within 2 hop local enclosing subgraph of Dtest\n",
    "            ## 2. Df is outside of 2 hop local enclosing subgraph of Dtest\n",
    "            \n",
    "            # All the candidate edges (train edges)\n",
    "            # graph = to_networkx(Data(edge_index=data.train_pos_edge_index, x=data.x))\n",
    "\n",
    "            # Get the 2 hop local enclosing subgraph for all test edges\n",
    "            _, local_edges, _, mask = k_hop_subgraph(\n",
    "                data.test_pos_edge_index.flatten().unique(), \n",
    "                2, \n",
    "                data.train_pos_edge_index, \n",
    "                num_nodes=dataset[0].num_nodes)\n",
    "            distant_edges = data.train_pos_edge_index[:, ~mask]\n",
    "            print('Number of edges. Local: ', local_edges.shape[1], 'Distant:', distant_edges.shape[1])\n",
    "\n",
    "            in_mask = mask\n",
    "            out_mask = ~mask\n",
    "\n",
    "            torch.save(\n",
    "                {'out': out_mask, 'in': in_mask},\n",
    "                os.path.join(data_dir, d, f'df_{s}.pt')\n",
    "            )\n",
    "\n",
    "process_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
